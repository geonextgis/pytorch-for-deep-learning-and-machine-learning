{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PyTorch NN Module**\n",
    "\n",
    "The torch.nn module in PyTorch is a core library that provides a wide array of classes and\n",
    "functions designed to help developers build neural networks efficiently and effectively. It\n",
    "abstracts the complexity of creating and training neural networks by offering pre-built layers,\n",
    "loss functions, activation functions, and other utilities, enabling you to focus on designing and\n",
    "experimenting with model architectures.\n",
    "\n",
    "**Key Components of torch.nn:**\n",
    "1. Modules (Layers):\n",
    "    - `nn.Module`: The base class for all neural network modules. Your custom models and\n",
    "    layers should subclass this class.\n",
    "    - Common Layers: Includes layers like `nn.Linear` (fully connected layer), `nn.Conv2d`\n",
    "    (convolutional layer), `nn.LSTM` (recurrent layer), and many others.\n",
    "\n",
    "2. Activation Functions:\n",
    "    - Functions like `nn.ReLU`, `nn.Sigmoid`, and `nn.Tanh` introduce non-linearities to the model, allowing it to learn complex patterns.\n",
    "\n",
    "3. Loss Functions:\n",
    "    - Provides loss functions such as `nn.CrossEntropyLoss`, `nn.MSELoss`, and `nn.NLLLoss` to quantify the difference between the model's predictions and the actual targets.\n",
    "\n",
    "4. Container Modules:\n",
    "    - `nn.Sequential`: A sequential container to stack layers in order.\n",
    "\n",
    "5. Regularization and Dropout:\n",
    "    - Layers like `nn.Dropout` and `nn.BatchNorm2d` help prevent overfitting and improve the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
       "0    842302         M  ...                  0.11890          NaN\n",
       "1    842517         M  ...                  0.08902          NaN\n",
       "2  84300903         M  ...                  0.08758          NaN\n",
       "3  84348301         M  ...                  0.17300          NaN\n",
       "4  84358402         M  ...                  0.07678          NaN\n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the breast cancer dataset using Pandas\n",
    "data = pd.read_csv(r\"D:\\GITHUB\\pytorch-for-deep-Learning-and-machine-learning\\datasets\\breast_cancer_data.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
       "0         M        17.99  ...          0.4601                  0.11890\n",
       "1         M        20.57  ...          0.2750                  0.08902\n",
       "2         M        19.69  ...          0.3613                  0.08758\n",
       "3         M        11.42  ...          0.6638                  0.17300\n",
       "4         M        20.29  ...          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the irrelevant columns\n",
    "data.drop(columns=['id', 'Unnamed: 32'], inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30), (398,), (171,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(columns=['diagnosis']),\n",
    "    data['diagnosis'],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 398 entries, 149 to 102\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              398 non-null    float64\n",
      " 1   texture_mean             398 non-null    float64\n",
      " 2   perimeter_mean           398 non-null    float64\n",
      " 3   area_mean                398 non-null    float64\n",
      " 4   smoothness_mean          398 non-null    float64\n",
      " 5   compactness_mean         398 non-null    float64\n",
      " 6   concavity_mean           398 non-null    float64\n",
      " 7   concave points_mean      398 non-null    float64\n",
      " 8   symmetry_mean            398 non-null    float64\n",
      " 9   fractal_dimension_mean   398 non-null    float64\n",
      " 10  radius_se                398 non-null    float64\n",
      " 11  texture_se               398 non-null    float64\n",
      " 12  perimeter_se             398 non-null    float64\n",
      " 13  area_se                  398 non-null    float64\n",
      " 14  smoothness_se            398 non-null    float64\n",
      " 15  compactness_se           398 non-null    float64\n",
      " 16  concavity_se             398 non-null    float64\n",
      " 17  concave points_se        398 non-null    float64\n",
      " 18  symmetry_se              398 non-null    float64\n",
      " 19  fractal_dimension_se     398 non-null    float64\n",
      " 20  radius_worst             398 non-null    float64\n",
      " 21  texture_worst            398 non-null    float64\n",
      " 22  perimeter_worst          398 non-null    float64\n",
      " 23  area_worst               398 non-null    float64\n",
      " 24  smoothness_worst         398 non-null    float64\n",
      " 25  compactness_worst        398 non-null    float64\n",
      " 26  concavity_worst          398 non-null    float64\n",
      " 27  concave points_worst     398 non-null    float64\n",
      " 28  symmetry_worst           398 non-null    float64\n",
      " 29  fractal_dimension_worst  398 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 96.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Print the column information\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30) (171, 30)\n"
     ]
    }
   ],
   "source": [
    "# Scale the input variables using standarad scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled =scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "# Encode the target variable using label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(y_train_encoded.shape, y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert NumPy Arrays to PyTorch Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([398, 30]) torch.Size([171, 30]) (398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train_scaled).type(torch.float32)\n",
    "X_test_tensor = torch.from_numpy(X_test_scaled).type(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(y_train_encoded).type(torch.float32)\n",
    "y_test_tensor = torch.from_numpy(y_test_encoded).type(torch.float32)\n",
    "\n",
    "print(X_train_tensor.shape, X_test_tensor.shape, y_train_encoded.shape, y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build a Simple NN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple neural network model with a single node\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        out = self.linear(X)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MySimpleNN                               --\n",
       "├─Linear: 1-1                            31\n",
       "├─Sigmoid: 1-2                           --\n",
       "=================================================================\n",
       "Total params: 31\n",
       "Trainable params: 31\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object of the model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "# Show the model summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and number of epoch\n",
    "lr = 0.1 # learning rate\n",
    "epochs = 25\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6484077572822571\n",
      "Epoch: 2, Loss: 0.31392422318458557\n",
      "Epoch: 3, Loss: 0.20721401274204254\n",
      "Epoch: 4, Loss: 0.1574023962020874\n",
      "Epoch: 5, Loss: 0.12950704991817474\n",
      "Epoch: 6, Loss: 0.11386612802743912\n",
      "Epoch: 7, Loss: 0.10390742868185043\n",
      "Epoch: 8, Loss: 0.09678122401237488\n",
      "Epoch: 9, Loss: 0.09131297469139099\n",
      "Epoch: 10, Loss: 0.08692934364080429\n",
      "Epoch: 11, Loss: 0.08334304392337799\n",
      "Epoch: 12, Loss: 0.08041228353977203\n",
      "Epoch: 13, Loss: 0.078069306910038\n",
      "Epoch: 14, Loss: 0.07627280801534653\n",
      "Epoch: 15, Loss: 0.07496736943721771\n",
      "Epoch: 16, Loss: 0.07406269013881683\n",
      "Epoch: 17, Loss: 0.07344499975442886\n",
      "Epoch: 18, Loss: 0.07300373166799545\n",
      "Epoch: 19, Loss: 0.07264965027570724\n",
      "Epoch: 20, Loss: 0.07231933623552322\n",
      "Epoch: 21, Loss: 0.0719723030924797\n",
      "Epoch: 22, Loss: 0.07158651947975159\n",
      "Epoch: 23, Loss: 0.07115405052900314\n",
      "Epoch: 24, Loss: 0.07067767530679703\n",
      "Epoch: 25, Loss: 0.0701679214835167\n"
     ]
    }
   ],
   "source": [
    "# Define a loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train_tensor)\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss in epoch\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.9443,  1.1426,  0.7460,  0.6416,  0.5991,  0.4249,  0.8939,  0.7191,\n",
      "          0.3031, -1.1574,  1.1007, -0.1218,  0.9625,  1.0889,  0.3460, -0.8296,\n",
      "         -0.2787,  0.5059, -0.5444, -1.1104,  0.9189,  1.2887,  0.8699,  0.9161,\n",
      "          0.9445,  0.5765,  0.6741,  0.6480,  0.8668,  0.1680]],\n",
      "       requires_grad=True)\n",
      "Model bias:\n",
      "Parameter containing:\n",
      "tensor([-0.9377], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print the model weights and bias\n",
    "print('Model weights:')\n",
    "print(model.linear.weight)\n",
    "\n",
    "print('Model bias:')\n",
    "print(model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data: 0.9941520690917969\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing data\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "# Calculate the accuracy using torchmetrics\n",
    "accuracy = Accuracy(task='binary')\n",
    "print('Accuracy on testing data:', accuracy(y_pred.squeeze(), y_test_tensor).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build a NN Model with a Hidden Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network with a hidden layers\n",
    "class MyComplexNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_feature):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features=num_feature, out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=3, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        out = self.linear1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the same model with sequential container\n",
    "class MyComplexNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 3), # input layer\n",
    "            nn.ReLU(), # activation\n",
    "            nn.Linear(3, 1), # hidden layer\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        out = self.network(X)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MyComplexNN                              --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       93\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       4\n",
       "│    └─Sigmoid: 2-4                      --\n",
       "=================================================================\n",
       "Total params: 97\n",
       "Trainable params: 97\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object of the model class\n",
    "model = MyComplexNN(X_train_tensor.shape[1])\n",
    "# Print the model summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the learning rate and number of epoch\n",
    "lr = 0.01\n",
    "epochs = 25\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7183933854103088\n",
      "Epoch: 2, Loss: 0.7053613066673279\n",
      "Epoch: 3, Loss: 0.6943788528442383\n",
      "Epoch: 4, Loss: 0.6850125193595886\n",
      "Epoch: 5, Loss: 0.6758115887641907\n",
      "Epoch: 6, Loss: 0.6664143204689026\n",
      "Epoch: 7, Loss: 0.6565479636192322\n",
      "Epoch: 8, Loss: 0.646085798740387\n",
      "Epoch: 9, Loss: 0.6351872682571411\n",
      "Epoch: 10, Loss: 0.6240401268005371\n",
      "Epoch: 11, Loss: 0.6128078699111938\n",
      "Epoch: 12, Loss: 0.6014628410339355\n",
      "Epoch: 13, Loss: 0.5900222659111023\n",
      "Epoch: 14, Loss: 0.5784705877304077\n",
      "Epoch: 15, Loss: 0.5668260455131531\n",
      "Epoch: 16, Loss: 0.5551018118858337\n",
      "Epoch: 17, Loss: 0.5432732105255127\n",
      "Epoch: 18, Loss: 0.5313003659248352\n",
      "Epoch: 19, Loss: 0.519077718257904\n",
      "Epoch: 20, Loss: 0.506550669670105\n",
      "Epoch: 21, Loss: 0.4936997592449188\n",
      "Epoch: 22, Loss: 0.4804483950138092\n",
      "Epoch: 23, Loss: 0.46678170561790466\n",
      "Epoch: 24, Loss: 0.4526923894882202\n",
      "Epoch: 25, Loss: 0.4382525086402893\n"
     ]
    }
   ],
   "source": [
    "# Define a loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # Loss calculation\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train_tensor)\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights:\n",
      "Parameter containing:\n",
      "tensor([[ 6.3411e-02,  1.9359e-01,  2.7810e-01,  2.9075e-01,  1.6261e-01,\n",
      "          1.8396e-01,  1.7374e-01,  3.5223e-01,  1.9172e-01, -1.6790e-01,\n",
      "          5.0785e-02,  6.2013e-02,  1.2589e-01,  2.2212e-01, -1.1851e-01,\n",
      "          2.5298e-04, -7.5342e-02,  1.2878e-01, -1.8251e-02, -3.0675e-02,\n",
      "          2.4538e-01,  3.1325e-01,  3.9837e-01,  2.2699e-01,  1.9796e-01,\n",
      "          3.4310e-01,  1.8602e-01,  3.7394e-01,  4.0327e-01,  1.2336e-01],\n",
      "        [ 2.1009e-01,  1.4024e-01,  3.1556e-01,  4.2080e-01,  2.3716e-01,\n",
      "          6.7354e-02,  1.3016e-01,  1.6799e-01,  1.6839e-01, -1.8712e-01,\n",
      "          8.9035e-02,  1.7247e-02,  2.3819e-01,  2.1984e-01, -2.3849e-01,\n",
      "         -1.0597e-01, -3.9944e-05,  1.7837e-01,  2.3280e-02, -1.8507e-01,\n",
      "          2.3217e-01,  7.4617e-02,  1.7397e-01,  3.1727e-01,  3.4675e-01,\n",
      "          3.8490e-01,  2.7170e-01,  2.2621e-01,  1.5601e-01,  2.5634e-01],\n",
      "        [-2.0629e-01, -2.5296e-01,  2.6603e-02, -1.0260e-01, -2.7529e-01,\n",
      "         -2.6626e-02, -1.5200e-01, -6.2477e-02,  6.8854e-02,  3.0287e-01,\n",
      "          1.8488e-02, -1.3977e-01, -2.5254e-01, -1.6169e-01,  1.3206e-01,\n",
      "          1.5751e-01,  2.3465e-01,  2.8301e-02,  5.7398e-02,  2.1035e-01,\n",
      "         -1.6233e-01, -2.2481e-01, -2.2377e-01, -2.5559e-01, -2.6044e-01,\n",
      "         -1.6533e-01,  4.2535e-02, -1.7928e-01, -2.6232e-02,  5.5502e-02]],\n",
      "       requires_grad=True)\n",
      "Model biases:\n",
      "Parameter containing:\n",
      "tensor([0.2519, 0.1264, 0.1217], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print the model weights and biases\n",
    "print('Model weights:')\n",
    "print(model.network[0].weight)\n",
    "print('Model biases:')\n",
    "print(model.network[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data: 0.9649122953414917\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing data\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "# Calculate the accuracy using torchmetrics\n",
    "accuracy = Accuracy(task='binary')\n",
    "print('Accuracy on testing data:', accuracy(y_pred.squeeze(), y_test_tensor).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
